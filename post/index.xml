<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Инфраструктура ИТ</title>
    <link>https://vitalyzhakov.github.io/post/</link>
    <description>Recent content in Posts on Инфраструктура ИТ</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ru-ru</language>
    <copyright>&amp;copy; 2018</copyright>
    <lastBuildDate>Sun, 01 Jan 2017 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://vitalyzhakov.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Генерация паспорта устройства</title>
      <link>https://vitalyzhakov.github.io/post/device-passport/</link>
      <pubDate>Mon, 13 Jun 2022 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/device-passport/</guid>
      <description>Часто в комплекте с устройствами поставляются их паспорта, которые содержат техническую спецификацию. На производстве выпускается несколько модификаций одного и того же устройства. Как сейчас - паспорта создаются путём копирования похожего и внесения в него изменений, что приводит к человеческим ошибкам.
Требования Основные параметры шаблона зависят от маркировки. Маркировка - это строка вида DSA XXXX DS XX XX XX, где каждый символ - выбор характеристики из словаря.
Кроме маркировки нужно указать точные характеристики, не вынесенные в маркировку (в том числе серийный номер).</description>
    </item>
    
    <item>
      <title>Масштабирование от нуля до миллиона пользователей</title>
      <link>https://vitalyzhakov.github.io/post/scaling-from-zero-to-millions-of-users/</link>
      <pubDate>Wed, 10 Nov 2021 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/scaling-from-zero-to-millions-of-users/</guid>
      <description>Настройка одного сервера Путь в тысячу миль начинается с первого шага и в проектировании сложных систем аналогично. Чтобы начать с чего-то простого, всегда запускаются на одном сервере.
Рисунок 1-1 демонстрирует одиночный сервер, в котором всё запущено на 1 сервере: веб приложение, база данных, кеш и т.д.
Для того, чтобы понять конфигурацию, полезно исследовать поток запроса и источники траффика. Давайте для начала посмотрим на движение запроса.
 Пользователи получают доступ к вебсайтам через доменные имена, такие как api.</description>
    </item>
    
    <item>
      <title>Системный дизайн, простой уровень</title>
      <link>https://vitalyzhakov.github.io/post/system-design-easy/</link>
      <pubDate>Fri, 01 Oct 2021 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/system-design-easy/</guid>
      <description>Рассмотрим в качестве простого примера сервис, доставляющий статическую веб страницу.
Факторами оценки могут быть:
 SL доступности сервиса; Время ответа на запрос клиента;  В самом простом варианте клиенты размещены в Москве.
Ограничения
 SL виртуальной машины (SLвм) = 99.95  Допущения
 мы в состоянии сделать сервис доставки страниц идеальным; нагрузкой на сервис пока пренебрежём.  Пусть сервис размещён в PRM.
Считаем факторы оценки
SL сервиса ~ SL nginx * SL вм, что примерно равно SL вм = 99.</description>
    </item>
    
    <item>
      <title>Схема CI/CD  для веб-разработчиков на основе open-source инструментов</title>
      <link>https://vitalyzhakov.github.io/post/ci-cd/</link>
      <pubDate>Mon, 22 Mar 2021 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/ci-cd/</guid>
      <description>Содержание
 Общая схема Сервер dev с песочницами Детализация разработки (создание ветки, непрерывный деплой и тестирование, создание merge на бота, апрув в master) Прод с master-master репликацией, graylog, sentry, prometheus.  Наверное, все видели стандартную восьмёрку, как выглядит CI/CD:
Но обычно никто не рассказывает, как именно реализовать этот процесс.
Сегодня детализирую этот на примере разработки веб-сервисов.
На схеме мы видим, как параллельно сдаются задачи (в виде коммитов) в master-ветку.</description>
    </item>
    
    <item>
      <title>Исключения и библиотеки</title>
      <link>https://vitalyzhakov.github.io/post/exception-in-libs/</link>
      <pubDate>Thu, 11 Feb 2021 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/exception-in-libs/</guid>
      <description>При создании библиотек часто возникает вопрос, прокидывать исключение наружу или ловить его в библиотеке?
Ответ прост)
Если библиотека знает, как поступить с исключением, стоит обработать его в библиотеке.
Если библиотека не знает, как поступить с исключением, стоит отдать обработку на уровень выше (в другую библиотеку или приложение).</description>
    </item>
    
    <item>
      <title>Исправляем ошибку fxp/composer-asset-plugin incompatible после обновления до composer 2</title>
      <link>https://vitalyzhakov.github.io/post/composer-2-fxp-asset-plugin/</link>
      <pubDate>Sat, 02 Jan 2021 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/composer-2-fxp-asset-plugin/</guid>
      <description>После обновления менеджера пакетов PHP composer до версии 2 появляется ошибка:
[RuntimeException] No composer.json present in the current directory, this may be the cause of the following exception. [InvalidArgumentException] Package fxp/composer-asset-plugin at version has a PHP requirement incompatible with your PHP version, PHP extensions and Composer version  Происходит из-за несовместимости fxp/composer-asset-plugin и composer версии 2.
Решение Удаляем старый плагин
composer global remove fxp/composer-asset-plugin  Если появляется ошибка, связанная с папками bower или npm, добавляем в config.</description>
    </item>
    
    <item>
      <title>Оптимизация обращений к базе данных</title>
      <link>https://vitalyzhakov.github.io/post/db-optimization/</link>
      <pubDate>Fri, 25 Dec 2020 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/db-optimization/</guid>
      <description>При разборе времени генерации ответа от сервера иногда узким местом может быть обращение к СУБД. Оптимизацию времени доступа к СУБД можно разделить на несколько видов:
Использование параметризованных запросов Некоторые программисты совершают ошибку, вписывая параметры (например, идентификаторы) запроса сразу в запрос. Первым шагом СУБД пытается проанализировать запрос. Если параметры приходят в запросе, в кеш запрос не складывается. Но если параметры прикладывать к запросу, структура запроса не меняется. Значит, при следующем запросе, есть вероятность нахождения проанализированной структуры в кеше, что позволит ускорить выполнение.</description>
    </item>
    
    <item>
      <title>Устранение ошибок SQL запросов в режиме ONLY_FULL_GROUP_BY</title>
      <link>https://vitalyzhakov.github.io/post/mysql-only-full-group-by/</link>
      <pubDate>Wed, 16 Sep 2020 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/mysql-only-full-group-by/</guid>
      <description>“Что случилось с моим приложением? Я установил новую версию MySQL. Запросы, что выполнялись на старой версии теперь падают с кучей ошибок.&amp;rdquo;
 Многие программисты сталкиваются с этим вопросом при обновлении до версий 5.7 или 8. В этой статье мы рассмотрим один из самых частых кейсов и его решение.
Мы говорим об этой ошибке
ERROR 1055 (42000): Expression #2 of SELECT list is not in GROUP BY clause and contains nonaggregated column &#39;test.</description>
    </item>
    
    <item>
      <title>Cron в распределённой системе</title>
      <link>https://vitalyzhakov.github.io/post/cron-requirements/</link>
      <pubDate>Fri, 28 Aug 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/cron-requirements/</guid>
      <description>Cron-задания часто являются одной из составляющих долгоживущего сервиса.
Могут применяться как сборщики мусора. Или как инициаторы заданий для воркеров.
Проблематика В большой распределённой системе cron-задания могут быть не рассчитаны на параллельную работу. Например, не реализовывать протокол Paxos
Поэтому требуется реализовать блокировку от параллельного выполнения.
Но начнём мы с часто совершаемой ошибки при полном цикле разработки и эксплуатации в разных отделах
cron находится в отличном от кода репо / настраивается вручную по заявке Предположу, что есть варианты, когда срок горит, а разбираться в CI/DevOps практиках лень.</description>
    </item>
    
    <item>
      <title>Ошибка с пространственным полем point при миграции из mysql 5.1 до mysql 8</title>
      <link>https://vitalyzhakov.github.io/post/migration-from-mysql-51-to-mysql-8-geometry-field/</link>
      <pubDate>Wed, 05 Aug 2020 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/migration-from-mysql-51-to-mysql-8-geometry-field/</guid>
      <description>Постановка задачи Был сервис на mysql 5.1. Нужно мигрировать на актуальную 8ю версию.
Заход с помощью mysql workbench не увенчался успехом, так как 5.1 уже давно не поддерживают.
mysqldump справился с задачей снять дамп, но при выполнении его на целевом сервере появились ошибки:
Cannot get geometry object from data you send to the GEOMETRY field  Диагностика Беглый поиск подводит к использованию mysqldump с ключом --hex-blob, но к результату это не приводит.</description>
    </item>
    
    <item>
      <title>VSCode for php</title>
      <link>https://vitalyzhakov.github.io/post/vscode-php/</link>
      <pubDate>Tue, 19 May 2020 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/vscode-php/</guid>
      <description> Работа с git по SSH Приватный ключ может быть защищён паролем, поэтому на Linux-based системах перед началом работы для использования такого ключа нужно воспользоваться командой
ssh-add ключ  Рекомендуемые расширения  vscode-intelephense-client code-spell-checker code-spell-checker-russian После установки в readme spell checker russian написано, как добавить русский язык в проверку. GitLens Remote development containers  </description>
    </item>
    
    <item>
      <title>Вычисление размеров изделия с помощью степеней свободы FreeCAD</title>
      <link>https://vitalyzhakov.github.io/post/freecad-degree-of-freedom/</link>
      <pubDate>Wed, 06 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/freecad-degree-of-freedom/</guid>
      <description>Недавно я столкнулся с простой бытовой потребностью - повесить полочки на стену. Так как стена плоская, полка должна опираться на уголки.
Вроде таких В магазине самые большие уголки длиной до 150 мм.
Ширина полки меня бы устроила ~300 мм, длина ~2 метра. Магазинный уголок, очевидно, не выдержит такую нагрузку.
В режиме самоизоляции ходить по магазинам не очень удобно, поэтому я решил немного прокачаться во FreeCAD и изготовить уголок самостоятельно.
Для увеличения прочности изделия уголок будет состоять из трёх частей:</description>
    </item>
    
    <item>
      <title>Graylog</title>
      <link>https://vitalyzhakov.github.io/post/graylog/</link>
      <pubDate>Fri, 24 Apr 2020 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/graylog/</guid>
      <description>В нашей жизни происходят разные события. Совсем разные. Например, люди заболевают коронавирусом.
Для различных прикладных задач важно знать, когда, на какой территории сколько человек заболело, чтобы своевременно действовать.
Как это происходит с точки зрения процесса:
 больного записывают в журнал с указанием важных атрибутов (дата, время, диагноз, место проживания); данные передаются на центральный узел сбора; специалисты анализируют данные, делают выводы.  Наши сервисы также могут отсылать события в централизованную систему (graylog).</description>
    </item>
    
    <item>
      <title>Репликация MySQL-серверов с помощью Docker</title>
      <link>https://vitalyzhakov.github.io/post/mysql-replication-docker/</link>
      <pubDate>Fri, 10 Apr 2020 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/mysql-replication-docker/</guid>
      <description>До выхода приложения в бой, нужно смоделировать его поведение в тестовой среде.
Технология Docker Swarm позволяет легко масштабировать приложение горизонтально. Но часто приложению приходится обращаться к серверу баз данных, задача масшабировать который гораздо труднее.
В нашем случае количество запросов на чтение информации гораздо меньше количества изменений (есть подозрение, что так на большинстве веб-проектов). Логичный способ увеличения такого бутылочного горлышка - увеличить количество баз на чтение и настроить приложение таким образом, чтобы большее количество запросов на чтение отправлялось на SLAVE-сервера.</description>
    </item>
    
    <item>
      <title>Оптимизация скорости загрузки</title>
      <link>https://vitalyzhakov.github.io/post/page-load-time-optimizing/</link>
      <pubDate>Mon, 03 Feb 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/page-load-time-optimizing/</guid>
      <description>Шаг 1. Постановка цели Основное на этом шаге - определиться, зачем вам оптимизировать скорость загрузки. К примеру, у вас сайт-визитка, продаёте вы бани под ключ. Продажи происходят в той же бане, за столом или по телефону.
Вполне возможно, что очередная секунда времени загрузки не влияет на продажи и вложенные затраты не окупятся.
Стоит сфокусироваться на тех сайтах или страницах, которые влияют на ваши целевые показатели.
Шаг 2. Сбор статистики и выбор узкого места для оптимизации Во-первых, обратимся к событиям, вызываевым на разных стадиях загрузки страницы:</description>
    </item>
    
    <item>
      <title>Почему мы не можем повлиять на чужие сайты</title>
      <link>https://vitalyzhakov.github.io/post/why-you-not-influence-aliens-site/</link>
      <pubDate>Thu, 23 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/why-you-not-influence-aliens-site/</guid>
      <description>Есть различные ресурсы, которые (якобы) выдают некие рекомендации по скорости загрузки страницы конкретного сайта. Далее будем называть его оптимизируемый сайт.
Рассмотрим рекомендацию для сайта известного федерального провайдера perm.domru.ru
Время жизни кеша задаётся в заголовках http-ответа. Рекомендация состоит в том, чтобы их изменить.
Как считаете, где надо менять?
Но пока не отвечайте =)
Цикл запроса Рассмотрим последовательность до конкретного ответа.
Браузер как http-клиент посылает запрос на доменное имя facebook.com
Компьютеры внутри сети общаются по IP адресам.</description>
    </item>
    
    <item>
      <title>Мониторинг</title>
      <link>https://vitalyzhakov.github.io/post/monitoring/</link>
      <pubDate>Tue, 01 Oct 2019 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/monitoring/</guid>
      <description>При растущем проекте количество часто сервисов также растёт.
Команда вносит в них изменения, но не все изменения удаётся протестировать.
Иногда ошибка проникает в продуктовую среду и по ней нужно отреагировать.
Один из способов отслеживания - сбор метрик и своевременная реакция на них. Представьте, что перед вами стоит задача обеспечения здоровья жителей города. Возможно, стоит периодически измерять показатели здоровья каждого жителя (температуру, давление, уровень сахара в крови), чтобы своевременно реагировать на изменения и предотвращать нежелательные последствия.</description>
    </item>
    
    <item>
      <title>Прогрессивное развёртывание</title>
      <link>https://vitalyzhakov.github.io/post/progressive-delivery/</link>
      <pubDate>Mon, 30 Sep 2019 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/progressive-delivery/</guid>
      <description>Проблематика В крупные проекты вносится много (больше 10) изменений в день.
С целью минимизации рисков можно вносить изменения на небольшие группы пользователей, постепенно увеличивая долю пользователей с новой версией в зависимости от успешности / не успешности метрик.
Метрики Как видно из постановки проблемы, успешность зависит от нескольких факторов:
 длительность принятия решения; вероятность принятия неправильного решения; количество изменений в единицу времени.  Выводы делаются на основе собираемых данных с сервисов (в идеале технических и бизнес-метрик).</description>
    </item>
    
    <item>
      <title>Автоматическое тестирование</title>
      <link>https://vitalyzhakov.github.io/post/autotesting/</link>
      <pubDate>Thu, 09 May 2019 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/autotesting/</guid>
      <description>На хорошем производстве существует входной и выходной контроль. Наверное, многие видели на технически сложных изделиях отметки ОТК, PASSED, QUALITY CHECK PASSED.
Приложение, упакованное в контейнер, тоже является технически сложным изделием. До развёртывания в боевой среде стоит смоделировать его поведение и протестировать.
Протестировать можно несколькими вариантами: * отдать заказчику; * проверить самому; * написать карточку тестирования; * написать автоматический тест.
Рассмотрим задачу публикации предварительно подготовленной промо-страницы в сети Интернет. Стандартная промо-страница состоит из картинок и текста с относительно неплохим дизайном.</description>
    </item>
    
    <item>
      <title>Нагрузочное тестирование</title>
      <link>https://vitalyzhakov.github.io/post/load-testing/</link>
      <pubDate>Wed, 12 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/load-testing/</guid>
      <description>Проблематика Запуск нагрузочного тестирования - довольно длительная процедура.
Если сервис держит нужное количество пользователей или расширение делалось разовыми изменениями параметров конфигруации, внедрять нагрузочное тестирование в процесс будет только замедлять Time To Market, но не улучшит вопрос качества.
Подготовка Договориться с заказчиком об SL  какое максимальное время ответа на каком сценарии должно быть (с распределением; какое количество пользователей должен выдерживать сервис в пиках.  Поправить все функциональные баги Перед тем, как начинать нагрузочное тестирование, нужно убедиться, что перед этим провели функциональное и поправили все баги.</description>
    </item>
    
    <item>
      <title>Переход от монолита к микросервисам</title>
      <link>https://vitalyzhakov.github.io/post/microservices/</link>
      <pubDate>Mon, 26 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/microservices/</guid>
      <description>Проблематика больших монолитных систем  Плохое горизонтальное масштабирование Плохая отказоустойчивость Сложность внедрения новых технологий Сложность рефакторинга legacy  Сравнение монолита и микросервисов    Монолит Микросервисы по доменам             Плюсы Минусы     Горизонтальное масштабирование только нужных частей Дополнительная сложность в тестировании и развёртывании   Отказоустойчивость Выше начальная стоимость   Масштабирование команд Не всегда согласованные данные   Гибкость стека Бывает трудно провести границу между сервисами    Вам не нужны микросервисы, если</description>
    </item>
    
    <item>
      <title>Git rebase для удалённой ветки</title>
      <link>https://vitalyzhakov.github.io/post/remote-rebase/</link>
      <pubDate>Thu, 30 Aug 2018 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/remote-rebase/</guid>
      <description> Командная строка  Клонируем репозиторий с указанием ветки, над которой будет выполнять операцию rebase
git clone [Адрес репозитория] -b [ветка]  Выполняем rebase локально
git pull --rebase origin master  Отправка данных на сервер
git push origin [ветка] -f   </description>
    </item>
    
    <item>
      <title>Замеры скорости загрузки вебсайтов</title>
      <link>https://vitalyzhakov.github.io/post/sitespeed/</link>
      <pubDate>Mon, 06 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/sitespeed/</guid>
      <description>Наиболее продвинутые компании на высококонкуретном рынке B2C понимают, что высокая скорость загрузки сайта положительно сказывается не только на имидже, но и на показателях конверсии.
Для того, чтобы что-то оптимизировать, нужно это замерить. В измерениях нам поможет инструмент под названием sitespeed.io.
В упрощённом варианте можно использовать всего 2 машины - 1 сервер и 1 клиент. Машины нужны изолированные, так как на измерения клиента не должны влиять операции на сервере.
Если потребуется, можно нарастить количество клиентов.</description>
    </item>
    
    <item>
      <title>Автоматическая проверка переадресации с помощью Codeception</title>
      <link>https://vitalyzhakov.github.io/post/redirect-autotest/</link>
      <pubDate>Tue, 05 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/redirect-autotest/</guid>
      <description>Рассмотрим реализацию теста, который подтверждает (проверяет) переадресацию пользователя на определённый URL.
На самом деле нам не нужно проверять, что пользователь перешёл на целевой URL. Задача веб-сервера заключается в том, чтобы отправить клиенту верный http-ответ с корректным заголовком и правильным статусом.
Далее уже клиент решает, переходить ему по этому URL или нет.
Пример конфигурации rest.suite.yml
actor: RestTester modules: enabled: - REST: depends: PhpBrowser url: http://адрес-сервера  Пример автоматической проверки
class RedirectCest{ public function autodiscoverRedirect(RestTester $I) { $I-&amp;gt;stopFollowingRedirects(); // запрещаем переходить по URL, чтобы отследить ответ сервера $I-&amp;gt;sendGET(&#39;/autodiscover/autodiscover.</description>
    </item>
    
    <item>
      <title>Тестирование API-интерфейсов над большими системами</title>
      <link>https://vitalyzhakov.github.io/post/rest-api-testing/</link>
      <pubDate>Thu, 31 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/rest-api-testing/</guid>
      <description>Постановка задачи Протестировать автоматическими скриптами валидность ответов API над большой системой.
Решение Для решения нам понадобится QA API.
В общем случае процесс выглядит следующим образом:
 скрипт с помощью QA API создаёт элемент данных, над которым будем проводить операции в проверяемом API. скрипт выполняет API-запросы с созданными элементами данных, для которых заранее известен ответ.  Пример системы - личный кабинет Протестируем API баланса личного кабинета пользователя.
Для этого:
 С помощью QA API создадим пользователя с указанным начальным значением баланса; С помощью rest API авторизуемся под пользователем; С помощью rest API проверим текущий баланс пользователя, сравним с балансом в пункте 1.</description>
    </item>
    
    <item>
      <title>API для автоматического тестирования</title>
      <link>https://vitalyzhakov.github.io/post/qa-api/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/qa-api/</guid>
      <description>В небольших проектах для воспроизведения тестов можно пользоваться следующим шагами:
 создать виртуальную машину (контейнер) с СУБД; восстановить СУБД с продуктовой среды из дампа; применить миграции.  Суть проблемы При больших базах даннных время восстановления может измеряться часами. Если мы ставим целью прохождение тестов в течение короткого интервала времени (до 10 минут), нам нужен другой подход.
Решение При написании обычного API программисты backend также пишут API для тестирования, которое создаёт сущности в бек-енде.</description>
    </item>
    
    <item>
      <title>Преимущества nginx unit</title>
      <link>https://vitalyzhakov.github.io/post/nginx-unit/</link>
      <pubDate>Mon, 14 May 2018 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/nginx-unit/</guid>
      <description>Упрощение архитектуры веб-сервера Стандартное web-приложение строится следующим образом
 клиент -&amp;gt; nginx -&amp;gt; php-fpm -&amp;gt; процесс php-fpm клиент -&amp;gt; nginx -&amp;gt; gunicorn клиент -&amp;gt; nginx -&amp;gt; uwsgi  В случае с nginx unit процесс может быть упрощён до клиент -&amp;gt; nginx unit с поддержкой соответствующего языка программирования.
nginx unit позволит убрать дополнительную прослойку, которая может генерировать ошибки 502&amp;frasl;504.
Конфигурация с помощью RESTful JSON API На некоторых проектах с частым внесением изменений опция может быть достаточно удобной.</description>
    </item>
    
    <item>
      <title>Импорт данных OpenStreetMap в PostgreSQL средствами osm2pgsql</title>
      <link>https://vitalyzhakov.github.io/post/osm2pgsql/</link>
      <pubDate>Fri, 11 May 2018 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/osm2pgsql/</guid>
      <description>На сайте бывает полезно отобразить географические данные, но простой интеграции с публичными проприетарными сервисами карт может не хватить. На помощь приходят открытые данные, для географических карт - это Openstreet Map.
Требования Действия выполняются на системе
 debian jessie 8.2; PostgreSQL 9.4; osm2pgsql 0.86; пользователь, от которого исполняется скрипт, должен иметь права на запись в целевую базу.  Подготовка базы Создаём БД gis, добавляем расширения postgis и hstore
createdb gis psql -d gis -c &#39;CREATE EXTENSION postgis; CREATE EXTENSION hstore&#39;  Импорт данных Найти географические координаты прямоугольника, который мы хотим импортировать можно на http://www.</description>
    </item>
    
    <item>
      <title>Автоматическое UI-тестирование в среде разработки</title>
      <link>https://vitalyzhakov.github.io/post/autotesting-in-sandbox/</link>
      <pubDate>Wed, 09 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/autotesting-in-sandbox/</guid>
      <description>Для комплексного тестирования приложения с веб-интерфейсом требуется selenium.
Суть проблемы Допустим, параллельно ведётся разработка 30 задач. Каждая задача требует индивидуальный контейнер с selenium для тестирования. Каждый контейнер с selenium требует 1-2 GB RAM и глючит, если его не перезапускать долгое время.
Решение До проведения тестов в CI прописывается удаление контейнера с selenium. После проведения тестов в CI прописывается удаление контейнера с selenium.
Теперь у нас память расходуется &amp;ldquo;по потребности&amp;rdquo;. Но при этом все пользователи обеспечены необходимым браузером для тестирования.</description>
    </item>
    
    <item>
      <title>Песочница (среда разработки) для веб-разработчиков</title>
      <link>https://vitalyzhakov.github.io/post/sandbox-for-web-developers/</link>
      <pubDate>Mon, 07 May 2018 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/sandbox-for-web-developers/</guid>
      <description>В системе контроля задач создаётся новый элемент с уникальным именем (порядковым номером). В репозитории проекта создаётся ветка с этим именем в нижнем регистре.
Раработчик вносит изменения в код и выполняет push на удалённый сервер. CI-сервер (gitlab) подхватывает это событие и создаёт задание worker для песочниц. Worker выполняет задание - разворачивает песочницу и добавляет в конфигурацию nginx уникальный домен, с которым может работать заказчик/тестировщик/аналитик и другие участники процесса.
Конфигурация worker:  много оперативной памяти (из расчёта количество задач в день, над которыми предстоит работать * количество контейнеров * количество потребляемой памяти на контейнер); 200 GB HDD в разделе /var/lib/docker для сборки контейнеров; docker-демон; docker-compose; хостовой nginx для проксирования сайтов - должен быть по умолчанию закрыт из внешки для коммерческих проектов; его конфигурация должна автоматически подтягивать конфигурации песочниц; хостовой consul для разрешения имён контейнеров в IP-адреса; скрипты для ночного удаления контейнеров; скрипты для ночного удаления песочниц.</description>
    </item>
    
    <item>
      <title>Примеры использования PostGis расширения в PostgreSQL</title>
      <link>https://vitalyzhakov.github.io/post/postgis-examples/</link>
      <pubDate>Tue, 23 Feb 2016 00:10:06 +0500</pubDate>
      
      <guid>https://vitalyzhakov.github.io/post/postgis-examples/</guid>
      <description>Здание (полигон), которое содержит точку с координатами $lng, $lat &amp;lt;?php &#39;SELECT * FROM planet_osm_polygon WHERE &#39; . &#39;ST_contains( way, ST_Transform( ST_SetSRID( ST_Point(&#39; . $lng . &#39;,&#39; . $lat . &#39;), 4326&#39; . &#39;), 900913 ) )&#39; . &amp;quot;AND building != &#39;&#39;&amp;quot;  Точки (организации) внутри найденного полигона &#39;SELECT point.* FROM planet_osm_point point, &#39; . &#39;planet_osm_polygon polygon &#39; . &#39;WHERE polygon.osm_id = &#39; . $polygon-&amp;gt;osm_id . &#39; AND ST_Contains (polygon.way, point.</description>
    </item>
    
  </channel>
</rss>